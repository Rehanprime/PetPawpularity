{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c52a9e5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-14T17:39:58.992787Z",
     "iopub.status.busy": "2022-01-14T17:39:58.988047Z",
     "iopub.status.idle": "2022-01-14T17:40:01.429901Z",
     "shell.execute_reply": "2022-01-14T17:40:01.429108Z",
     "shell.execute_reply.started": "2022-01-14T17:35:47.291525Z"
    },
    "papermill": {
     "duration": 2.466935,
     "end_time": "2022-01-14T17:40:01.430061",
     "exception": false,
     "start_time": "2022-01-14T17:39:58.963126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch,os\n",
    "from torchvision import datasets ,transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset,DataLoader,Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch import optim\n",
    "from torch.utils.data import random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f3a82b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:40:01.461370Z",
     "iopub.status.busy": "2022-01-14T17:40:01.459736Z",
     "iopub.status.idle": "2022-01-14T17:40:03.049450Z",
     "shell.execute_reply": "2022-01-14T17:40:03.048835Z",
     "shell.execute_reply.started": "2022-01-14T17:35:47.523789Z"
    },
    "papermill": {
     "duration": 1.605689,
     "end_time": "2022-01-14T17:40:03.049589",
     "exception": false,
     "start_time": "2022-01-14T17:40:01.443900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master/')\n",
    "import timm\n",
    "from timm import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f297f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:40:03.076649Z",
     "iopub.status.busy": "2022-01-14T17:40:03.076075Z",
     "iopub.status.idle": "2022-01-14T17:40:03.112195Z",
     "shell.execute_reply": "2022-01-14T17:40:03.111519Z",
     "shell.execute_reply.started": "2022-01-14T17:35:47.673897Z"
    },
    "papermill": {
     "duration": 0.051628,
     "end_time": "2022-01-14T17:40:03.112334",
     "exception": false,
     "start_time": "2022-01-14T17:40:03.060706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data=pd.read_csv('../input/petfinder-pawpularity-score/train.csv')\n",
    "test_data=pd.read_csv('../input/petfinder-pawpularity-score/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660d3d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:40:03.142077Z",
     "iopub.status.busy": "2022-01-14T17:40:03.141278Z",
     "iopub.status.idle": "2022-01-14T17:40:03.143729Z",
     "shell.execute_reply": "2022-01-14T17:40:03.143296Z",
     "shell.execute_reply.started": "2022-01-14T17:35:47.831188Z"
    },
    "papermill": {
     "duration": 0.020034,
     "end_time": "2022-01-14T17:40:03.143867",
     "exception": false,
     "start_time": "2022-01-14T17:40:03.123833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#dataset for testing\n",
    "class ImageDataset_test(Dataset):\n",
    "    \n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):\n",
    "        self.img_id = test_data[['Id']].copy()\n",
    "        self.img_dir = img_dir \n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_id)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_id.iloc[idx, 0])\n",
    "        image = read_image(img_path+'.jpg')\n",
    "        image_id = self.img_id.iloc[idx,0]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image,image_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb9242e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:40:03.173357Z",
     "iopub.status.busy": "2022-01-14T17:40:03.172780Z",
     "iopub.status.idle": "2022-01-14T17:40:35.062829Z",
     "shell.execute_reply": "2022-01-14T17:40:35.062342Z",
     "shell.execute_reply.started": "2022-01-14T17:35:48.023728Z"
    },
    "papermill": {
     "duration": 31.908215,
     "end_time": "2022-01-14T17:40:35.062961",
     "exception": false,
     "start_time": "2022-01-14T17:40:03.154746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model1=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "model2=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "model3=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "model4=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "model5=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "\n",
    "model6=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "model7=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "model8=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "model9=create_model('swin_large_patch4_window7_224',pretrained=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf827df6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:40:35.102809Z",
     "iopub.status.busy": "2022-01-14T17:40:35.093291Z",
     "iopub.status.idle": "2022-01-14T17:40:35.294934Z",
     "shell.execute_reply": "2022-01-14T17:40:35.294412Z",
     "shell.execute_reply.started": "2022-01-14T17:36:20.094332Z"
    },
    "papermill": {
     "duration": 0.220732,
     "end_time": "2022-01-14T17:40:35.295070",
     "exception": false,
     "start_time": "2022-01-14T17:40:35.074338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model1.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model1.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model1.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model1.to('cuda:0')\n",
    "\n",
    "model4.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model4.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model4.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model4.to('cuda:0')\n",
    "\n",
    "\n",
    "\n",
    "model3.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model3.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model3.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model3.to('cuda:0')\n",
    "\n",
    "model2.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model2.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model2.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model2.to('cuda:0')\n",
    "\n",
    "model5.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model5.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model5.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model2.to('cuda:0')\n",
    "\n",
    "model6.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model6.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model6.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model2.to('cuda:0')\n",
    "\n",
    "model7.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model7.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model7.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model2.to('cuda:0')\n",
    "\n",
    "model8.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model8.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model8.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model2.to('cuda:0')\n",
    "\n",
    "model9.head=nn.Sequential(nn.Linear(1536,64),nn.BatchNorm1d(64),nn.ReLU(),nn.Linear(64,1))\n",
    "for param in model9.parameters():\n",
    "    param.require_grad=False\n",
    "for param in model9.head.parameters():\n",
    "    param.require_grad=True\n",
    "#model2.to('cuda:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6efd6067",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:40:35.325947Z",
     "iopub.status.busy": "2022-01-14T17:40:35.325062Z",
     "iopub.status.idle": "2022-01-14T17:41:43.899169Z",
     "shell.execute_reply": "2022-01-14T17:41:43.899609Z",
     "shell.execute_reply.started": "2022-01-14T17:36:20.144347Z"
    },
    "papermill": {
     "duration": 68.59327,
     "end_time": "2022-01-14T17:41:43.899798",
     "exception": false,
     "start_time": "2022-01-14T17:40:35.306528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): BasicLayer(\n",
       "      dim=192, input_resolution=(56, 56), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(56, 56), dim=192\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=384, input_resolution=(28, 28), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(28, 28), dim=384\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=768, input_resolution=(14, 14), depth=18\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(14, 14), dim=768\n",
       "        (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
       "        (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=1536, input_resolution=(7, 7), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=64, bias=True)\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load('../input/5folds-no-finetuning/model_1_weights.pth'))\n",
    "model1.to('cuda:0')\n",
    "model2.load_state_dict(torch.load('../input/5folds-no-finetuning/model_2_weights.pth'))\n",
    "model2.to('cuda:0')\n",
    "model3.load_state_dict(torch.load('../input/5folds-no-finetuning/model_3_weights.pth'))\n",
    "model3.to('cuda:0')\n",
    "model4.load_state_dict(torch.load('../input/5folds-no-finetuning/model_4_weights.pth'))\n",
    "model4.to('cuda:0')\n",
    "model5.load_state_dict(torch.load('../input/5folds-no-finetuning/model_5_weights.pth'))\n",
    "model5.to('cuda:0')\n",
    "\n",
    "model6.load_state_dict(torch.load('../input/transformers/model1_weights.pth'))\n",
    "model6.to('cuda:0')\n",
    "\n",
    "\n",
    "model7.load_state_dict(torch.load('../input/transformers/model2_weights.pth'))\n",
    "model7.to('cuda:0')\n",
    "model8.load_state_dict(torch.load('../input/transformers/model3_weights.pth'))\n",
    "model8.to('cuda:0')\n",
    "model9.load_state_dict(torch.load('../input/transformers/model4_weights.pth'))\n",
    "model9.to('cuda:0') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0596904",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:41:43.937248Z",
     "iopub.status.busy": "2022-01-14T17:41:43.933358Z",
     "iopub.status.idle": "2022-01-14T17:41:43.940355Z",
     "shell.execute_reply": "2022-01-14T17:41:43.939846Z",
     "shell.execute_reply.started": "2022-01-14T17:37:41.873145Z"
    },
    "papermill": {
     "duration": 0.02825,
     "end_time": "2022-01-14T17:41:43.940471",
     "exception": false,
     "start_time": "2022-01-14T17:41:43.912221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset =  ImageDataset_test(img_dir='../input/petfinder-pawpularity-score/test/',transform=transforms.Compose([\n",
    "    transforms.Resize(256),transforms.CenterCrop(224), \n",
    "     transforms.ConvertImageDtype(torch.float), transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225])]))\n",
    "test_data_loader=DataLoader(test_dataset,batch_size=1,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9268f920",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:41:43.968588Z",
     "iopub.status.busy": "2022-01-14T17:41:43.967927Z",
     "iopub.status.idle": "2022-01-14T17:41:44.076288Z",
     "shell.execute_reply": "2022-01-14T17:41:44.075606Z",
     "shell.execute_reply.started": "2022-01-14T17:37:41.882696Z"
    },
    "papermill": {
     "duration": 0.123878,
     "end_time": "2022-01-14T17:41:44.076423",
     "exception": false,
     "start_time": "2022-01-14T17:41:43.952545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgboost_model=torch.load('../input/xgboost/xgboost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f42e3bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:41:44.104899Z",
     "iopub.status.busy": "2022-01-14T17:41:44.104072Z",
     "iopub.status.idle": "2022-01-14T17:41:53.245275Z",
     "shell.execute_reply": "2022-01-14T17:41:53.244662Z",
     "shell.execute_reply.started": "2022-01-14T17:39:26.255813Z"
    },
    "papermill": {
     "duration": 9.156863,
     "end_time": "2022-01-14T17:41:53.245425",
     "exception": false,
     "start_time": "2022-01-14T17:41:44.088562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_out_data=[]\n",
    "test_id_data=[]\n",
    "for i,(test_img,test_id) in enumerate(test_data_loader):\n",
    "    \n",
    "    test_img=test_img.to('cuda:0')\n",
    "    model1.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out1=abs(model1(test_img))\n",
    "        test_out1=test_out1.to('cpu')\n",
    "        \n",
    "    model2.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out2=abs(model2(test_img))\n",
    "        test_out2=test_out2.to('cpu')\n",
    "   \n",
    "    model3.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out3=abs(model3(test_img))\n",
    "        test_out3=test_out3.to('cpu')\n",
    "    \n",
    "    model4.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out4=abs(model4(test_img))\n",
    "        test_out4=test_out4.to('cpu')\n",
    " \n",
    "    model5.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out6=abs(model5(test_img))\n",
    "        test_out6=test_out6.to('cpu')\n",
    "        \n",
    "        \n",
    "        \n",
    " \n",
    "    model6.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out7=abs(model6(test_img))\n",
    "        test_out7=test_out7.to('cpu') \n",
    "    \n",
    "    \n",
    "    model7.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out8=abs(model7(test_img))\n",
    "        test_out8=test_out8.to('cpu')\n",
    "        \n",
    " \n",
    "    model8.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out9=abs(model8(test_img))\n",
    "        test_out9=test_out9.to('cpu')\n",
    "\n",
    " \n",
    "    model9.eval()\n",
    "    with torch.no_grad():\n",
    "        test_out10=abs(model9(test_img))\n",
    "        test_out10=test_out10.to('cpu')        \n",
    "    features=['Subject Focus','Eyes','Face','Near','Action','Accessory','Group','Collage','Human','Occlusion','Info','Blur']\n",
    "    \n",
    "    X=test_data[features][test_data.Id==test_id[0]]\n",
    "    test_out5=xgboost_model.predict(X)\n",
    "    \n",
    "    test_out=(test_out1+test_out2+test_out3+test_out4+ test_out5+test_out6 +test_out7 +test_out8 +test_out9 +test_out10 )/10.0\n",
    "    test_out_data.append(test_out)\n",
    "    test_id_data.append(test_id)\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------    \n",
    "test_out_data=np.array(test_out_data)\n",
    "test_id_data=np.array(test_id_data)\n",
    "test_id_data=np.reshape(test_id_data,test_id_data.shape[0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa9f81ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:41:53.278869Z",
     "iopub.status.busy": "2022-01-14T17:41:53.278144Z",
     "iopub.status.idle": "2022-01-14T17:41:53.288931Z",
     "shell.execute_reply": "2022-01-14T17:41:53.289483Z",
     "shell.execute_reply.started": "2022-01-14T17:37:44.073086Z"
    },
    "papermill": {
     "duration": 0.031212,
     "end_time": "2022-01-14T17:41:53.289650",
     "exception": false,
     "start_time": "2022-01-14T17:41:53.258438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pawpularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4128bae22183829d2b5fea10effdb0c3</th>\n",
       "      <td>44.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43a2262d7738e3d420d453815151079e</th>\n",
       "      <td>42.524227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4e429cead1848a298432a0acad014c9d</th>\n",
       "      <td>43.878700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80bc3ccafcc51b66303c2c263aa38486</th>\n",
       "      <td>44.878677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8f49844c382931444e68dffbe20228f4</th>\n",
       "      <td>44.407829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b03f7041962238a7c9d6537e22f9b017</th>\n",
       "      <td>44.889381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c978013571258ed6d4637f6e8cc9d6a3</th>\n",
       "      <td>42.641228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e0de453c1bffc20c22b072b34b54e50f</th>\n",
       "      <td>42.652302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Pawpularity\n",
       "Id                                           \n",
       "4128bae22183829d2b5fea10effdb0c3    44.811321\n",
       "43a2262d7738e3d420d453815151079e    42.524227\n",
       "4e429cead1848a298432a0acad014c9d    43.878700\n",
       "80bc3ccafcc51b66303c2c263aa38486    44.878677\n",
       "8f49844c382931444e68dffbe20228f4    44.407829\n",
       "b03f7041962238a7c9d6537e22f9b017    44.889381\n",
       "c978013571258ed6d4637f6e8cc9d6a3    42.641228\n",
       "e0de453c1bffc20c22b072b34b54e50f    42.652302"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "submit=pd.DataFrame({'Id':test_id_data,'Pawpularity':test_out_data})\n",
    "submit.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7a2a3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-14T17:41:53.322092Z",
     "iopub.status.busy": "2022-01-14T17:41:53.321207Z",
     "iopub.status.idle": "2022-01-14T17:41:53.328073Z",
     "shell.execute_reply": "2022-01-14T17:41:53.327598Z",
     "shell.execute_reply.started": "2022-01-14T17:37:44.092613Z"
    },
    "papermill": {
     "duration": 0.024208,
     "end_time": "2022-01-14T17:41:53.328199",
     "exception": false,
     "start_time": "2022-01-14T17:41:53.303991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "submit.to_csv('submission.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9214c1b1",
   "metadata": {
    "papermill": {
     "duration": 0.012241,
     "end_time": "2022-01-14T17:41:53.354807",
     "exception": false,
     "start_time": "2022-01-14T17:41:53.342566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d8bcdd",
   "metadata": {
    "papermill": {
     "duration": 0.012204,
     "end_time": "2022-01-14T17:41:53.379507",
     "exception": false,
     "start_time": "2022-01-14T17:41:53.367303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c1e2fb",
   "metadata": {
    "papermill": {
     "duration": 0.012032,
     "end_time": "2022-01-14T17:41:53.404120",
     "exception": false,
     "start_time": "2022-01-14T17:41:53.392088",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 125.346292,
   "end_time": "2022-01-14T17:41:56.319877",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-14T17:39:50.973585",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
